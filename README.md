# OmniDoc

OmniDoc is a **local, LLM-powered document intelligence system** for querying, summarizing, and extracting information from **PDF and DOCX documents**, including diagrams and figures inside PDFs.

It combines **Retrieval-Augmented Generation (RAG)** with **image understanding** to answer questions strictly using document content.

---

## ğŸš€ Features

- ğŸ“„ Question answering over documents
- ğŸ§  Automatic intent detection (QA / summary / extraction)
- ğŸ“š RAG-based retrieval for large documents
- ğŸ“Š Diagram & image extraction from PDFs
- ğŸ–¼ï¸ Image captioning using BLIP
- ğŸ” Context-only answers (hallucination controlled)
- ğŸ–¥ï¸ Streamlit-based UI
- ğŸ” Runs fully locally using Ollama

---

## ğŸ§  How It Works

1. User uploads a PDF or DOCX file  
2. Text is extracted from the document  
3. *(PDF only)* Images are extracted using PyMuPDF  
4. Images are captioned using BLIP  
5. Captions are merged into document context  
6. Document is indexed using embeddings  
7. User query intent is detected  
8. Relevant chunks are retrieved via RAG  
9. LLM answers **strictly from retrieved context**  
10. Relevant diagrams are shown **only when useful**

---

## ğŸ§° Tech Stack

### UI
- Streamlit

### LLM
- Mistral (via Ollama)

### Embeddings
- `nomic-embed-text`

### RAG
- Custom in-memory pipeline

### Document Parsing
- PDF: PyMuPDF  
- DOCX: python-docx

### Image Understanding
- Image Captioning: BLIP  
- Image Processing: Pillow

---

## ğŸ—‚ï¸ Project Structure

```text
OmniDoc/
â”‚
â”œâ”€â”€ app.py                # Streamlit UI
â”œâ”€â”€ pipeline.py           # CLI pipeline
â”œâ”€â”€ loader.py             # Document loaders
â”œâ”€â”€ rag.py                # RAG logic
â”œâ”€â”€ intent.py             # Intent detection
â”œâ”€â”€ router.py             # Task routing
â”œâ”€â”€ llm.py                # LLM interface
â”œâ”€â”€ image_loader.py       # Image extraction & captioning
â”œâ”€â”€ README.md


â¸»

âš ï¸ Current Limitations
	â€¢	Image relevance is caption-based (no vision embeddings yet)
	â€¢	Duplicate images can appear in PDFs with reused assets
	â€¢	Image ranking is keyword-based (semantic ranking pending)

â¸»

ğŸ”® Planned Improvements
	â€¢	Vision embeddings for semantic image retrieval
	â€¢	Image deduplication using perceptual hashing
	â€¢	Cross-modal (text â†” image) relevance scoring
	â€¢	Persistent vector store (FAISS / Chroma)
	â€¢	Multi-document support

â¸»

ğŸ§ª Local Setup

pip install -r requirements.txt
ollama pull mistral
streamlit run app.py


â¸»

ğŸ“Œ Why OmniDoc?
	â€¢	Fully local and privacy-preserving
	â€¢	No hallucinated answers
	â€¢	Designed for technical, academic, and enterprise documents
	â€¢	Extensible to multimodal RAG systems

---

## Final blunt truth

- Your **logic and content were solid**
- Your **Markdown formatting was wrong**
- GitHub was doing exactly what it should

This version will render **perfectly point-wise** in GitHub view.

If you want next:
- TL/interview **explanation version**
- Defense/research-oriented README
- Architecture diagram (text or visual)

Say the word.
